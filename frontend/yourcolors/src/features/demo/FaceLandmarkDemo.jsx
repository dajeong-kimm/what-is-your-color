// ğŸ“Œ FaceLandmarkDemo.jsx
import React, { useEffect, useRef } from "react";
import { FilesetResolver, FaceLandmarker } from "@mediapipe/tasks-vision";
import "./FaceLandmarkDemo.css"; // ìŠ¤íƒ€ì¼ë§ì„ ìœ„í•œ CSS

const FaceLandmarkDemo = () => {
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const faceLandmarkerRef = useRef(null);
  const animationFrameRef = useRef(null);

  // ğŸŸ¡ 1. Mediapipe FaceLandmarker ì„¤ì •
  const setupFaceLandmarker = async () => {
    const vision = await FilesetResolver.forVisionTasks(
      "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/wasm"
    );

    const faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
      baseOptions: {
        modelAssetPath:
          "https://storage.googleapis.com/mediapipe-assets/face_landmarker.task",
        delegate: "GPU",
      },
      runningMode: "VIDEO",
      numFaces: 1,
    });

    faceLandmarkerRef.current = faceLandmarker;
  };

  // ğŸŸ¡ 2. ì¹´ë©”ë¼ ì‹œì‘
  const startCamera = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "user" },
      });
      videoRef.current.srcObject = stream;
      videoRef.current.play();
      detectFaces();
    } catch (error) {
      console.error("ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨:", error);
    }
  };

  // ğŸŸ¡ 3. ì–¼êµ´ ì¸ì‹ ë° ì‹œê°í™”
  const detectFaces = async () => {
    if (
      !faceLandmarkerRef.current ||
      !videoRef.current ||
      !canvasRef.current
    ) {
      animationFrameRef.current = requestAnimationFrame(detectFaces);
      return;
    }

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext("2d");

    // ìº”ë²„ìŠ¤ í¬ê¸° ì„¤ì •
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    // ì–¼êµ´ ì¸ì‹
    const results = await faceLandmarkerRef.current.detectForVideo(
      video,
      performance.now()
    );

    // ë¹„ë””ì˜¤ë¥¼ ì¢Œìš° ë°˜ì „í•˜ë©° ìº”ë²„ìŠ¤ì— ì¶œë ¥
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.save();
    ctx.translate(canvas.width, 0);
    ctx.scale(-1, 1);
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    ctx.restore();

    // ğŸŸ¢ ì–¼êµ´ ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
    if (results.faceLandmarks.length > 0) {
      const landmarks = results.faceLandmarks[0];

      // ëœë“œë§ˆí¬ í¬ì¸íŠ¸ í‘œì‹œ
      ctx.fillStyle = "#00FF00";
      ctx.font = "12px Arial";

      landmarks.forEach((point, index) => {
        const x = (1 - point.x) * canvas.width;
        const y = point.y * canvas.height;

        // ğŸ”µ ì  í‘œì‹œ
        ctx.beginPath();
        ctx.arc(x, y, 3, 0, 2 * Math.PI);
        ctx.fill();

        // ğŸ”´ ëœë“œë§ˆí¬ ë²ˆí˜¸ ë¼ë²¨ë§
        ctx.fillStyle = "#FF0000";
        ctx.fillText(`${index}`, x + 5, y - 5);
      });

      // ì–¼êµ´ ìœ¤ê³½ì„  ì—°ê²°
      drawLine(ctx, landmarks, FACE_OUTLINE, "#FFD700", 2);
      drawLine(ctx, landmarks, LEFT_EYE, "#00FFFF", 2);
      drawLine(ctx, landmarks, RIGHT_EYE, "#00FFFF", 2);
      drawLine(ctx, landmarks, LIPS, "#FF69B4", 2);
    }

    animationFrameRef.current = requestAnimationFrame(detectFaces);
  };

  // ğŸŸ¡ 4. ëœë“œë§ˆí¬ ì—°ê²°ì„  ê·¸ë¦¬ê¸° í•¨ìˆ˜
  const drawLine = (ctx, landmarks, indices, color, lineWidth) => {
    ctx.beginPath();
    ctx.strokeStyle = color;
    ctx.lineWidth = lineWidth;

    indices.forEach((index, i) => {
      const point = landmarks[index];
      const x = (1 - point.x) * canvasRef.current.width;
      const y = point.y * canvasRef.current.height;
      if (i === 0) {
        ctx.moveTo(x, y);
      } else {
        ctx.lineTo(x, y);
      }
    });
    ctx.closePath();
    ctx.stroke();
  };

  // ğŸŸ¡ 5. ëœë“œë§ˆí¬ í¬ì¸íŠ¸ ë°°ì—´ ì •ì˜ (Mediapipe ê¸°ë°˜)
  const FACE_OUTLINE = [
    10, 338, 297, 332, 284, 251, 389, 356, 454, 323,
    361, 288, 397, 365, 379, 378, 400, 377, 152, 148,
    176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162,
  ];
  const LEFT_EYE = [33, 133, 160, 159, 158, 157, 173, 133];
  const RIGHT_EYE = [263, 362, 387, 386, 385, 384, 398, 362];
  const LIPS = [
    61, 146, 91, 181, 84, 17, 314, 405, 321, 375,
    291, 308, 324, 318, 402, 317, 14, 87, 178, 88,
  ];

  // ğŸŸ¡ 6. ì»´í¬ë„ŒíŠ¸ ì‹¤í–‰ ì‹œ ì´ˆê¸°í™”
  useEffect(() => {
    setupFaceLandmarker();
    startCamera();
    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (videoRef.current?.srcObject) {
        videoRef.current.srcObject.getTracks().forEach((track) => track.stop());
      }
    };
  }, []);

  return (
    <div className="face-landmark-demo">
      {/* ğŸ“¹ ë¹„ë””ì˜¤ ìš”ì†Œ */}
      <video
        ref={videoRef}
        autoPlay
        playsInline
        style={{ display: "none" }}
      />
      {/* ğŸ–Œï¸ ì–¼êµ´ ëœë“œë§ˆí¬ ìº”ë²„ìŠ¤ */}
      <canvas ref={canvasRef} className="overlay-canvas" />
    </div>
  );
};

export default FaceLandmarkDemo;
