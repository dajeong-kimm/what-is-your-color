// ai-model, ì–¼êµ´ë§Œ ë³´ë‚´ëŠ” ë²„ì „
import React, { useRef, useEffect, useState } from "react";
import { Holistic } from "@mediapipe/holistic";
// import { Camera } from "@mediapipe/camera_utils";
import { useNavigate } from "react-router-dom";
import axios from "axios";
import useStore from "../../store/UseStore"; //Zustand ìƒíƒœê´€ë¦¬ ë°ì´í„°
import { useModalStore } from "../../store/useModalStore"; // Zustand ëª¨ë‹¬ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
import DiagFailModalComponent from "../diagnosis/DiagFailModalComponent"; //ì§„ë‹¨ ì‹¤íŒ¨ ì‹œ ì‹¤íŒ¨ ëª¨ë‹¬
import useWebcamStore from "../../store/useWebcamStore"; // Zustand ì¹´ë©”ë¼ ìƒíƒœ ê´€ë¦¬

const apiBaseUrl = import.meta.env.VITE_API_BASE_URL;

const MediapipeCameraXTimerAI = () => {
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const holisticRef = useRef(null); // Holistic ì¸ìŠ¤í„´ìŠ¤ ì €ì¥ìš©

  const [countdown, setCountdown] = useState(null);
  const [capturedImage, setCapturedImage] = useState(null);
  const [showCaptureButton, setShowCaptureButton] = useState(true);
  const [isFlashing, setIsFlashing] = useState(false);
  const [hasCaptured, setHasCaptured] = useState(false); // ì´ë¯¸ ì´¬ì˜í–ˆëŠ”ì§€ ì²´í¬
  const [faceBlob, setFaceBlob] = useState(null);

  const navigate = useNavigate();
  const {
    userPersonalId,
    setUserPersonalId,
    fetchPersonalColorDetails,
    userImageFile,
    setUserImageFile,
    setResults,
    gptSummary,
    setGptSummary,
    setQrImage,
  } = useStore(); //Zustand ìƒíƒœê´€ë¦¬ ë°ì´í„°
  const { openModal } = useModalStore(); // ëª¨ë‹¬ ìƒíƒœ
  const { stream, startCamera, stopCamera } = useWebcamStore();

  useEffect(() => {
    if (stream && videoRef.current) {
      videoRef.current.srcObject = stream;
      // videoRef.current
      //   .play()
      //   .catch((error) => console.error("Play ì˜¤ë¥˜:", error));
    }
  }, [stream]);

  useEffect(() => {
    startCamera();
    return () => stopCamera(); // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì¹´ë©”ë¼ ì •ì§€
  }, [startCamera, stopCamera]);

  useEffect(() => {
    const setupHolistic = async () => {
      const holistic = new Holistic({
        locateFile: (file) =>
          `https://cdn.jsdelivr.net/npm/@mediapipe/holistic/${file}`,
      });
      holistic.setOptions({
        modelComplexity: 1,
        smoothLandmarks: true,
        refineFaceLandmarks: true,
      });
      holistic.onResults(() => {
        if (!canvasRef.current || !videoRef.current) return;
        const ctx = canvasRef.current.getContext("2d");
        ctx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);
        ctx.drawImage(
          videoRef.current,
          0,
          0,
          canvasRef.current.width,
          canvasRef.current.height
        );
      });
      holisticRef.current = holistic;
    };

    setupHolistic();
  }, []);

  const handleCapture = async () => {
    // ë²„íŠ¼ í´ë¦­ ì‹œ ì¤‘ë³µ í´ë¦­ ë°©ì§€
    setShowCaptureButton(false);

    console.log("[handleCapture] Start 5s countdown");
    setCapturedImage(null);
    setHasCaptured(false);
    setCountdown(5);

    const timer = setInterval(() => {
      setCountdown((prev) => {
        if (prev === 1) {
          clearInterval(timer);
          console.log("[handleCapture] Time is up -> capturePhoto()");
          capturePhoto();
          return null;
        }
        return prev - 1;
      });
    }, 1000);
  };

  const capturePhoto = () => {
    if (hasCaptured) {
      console.log("[capturePhoto] Already captured -> skip");
      return;
    }
    setHasCaptured(true);

    console.log("[capturePhoto] Capturing now...");
    setIsFlashing(true);

    setTimeout(() => {
      setIsFlashing(false);
      const canvas = canvasRef.current;
      const video = videoRef.current;

      if (canvas && video) {
        const context = canvas.getContext("2d");
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        context.save();
        context.scale(-1, 1);
        context.drawImage(video, -canvas.width, 0, canvas.width, canvas.height);
        context.restore();

        const imageData = canvas.toDataURL("image/png");
        console.log("Captured Image (base64):", imageData);
        setCapturedImage(imageData);
        setCountdown(null);

        // ì–¼êµ´ ë¶€ë¶„ ì¶”ì¶œ
        const faceImage = extractFaceImage(canvas);
        console.log("Extracted Face Image (base64):", faceImage);

        // Base64 â†’ Blob ë³€í™˜
        const blob = base64ToBlob(faceImage, "image/png");
        // faceBlob ìƒíƒœ ì—…ë°ì´íŠ¸ (ë‘ APIì—ì„œ ì‚¬ìš©)
        setFaceBlob(blob);

        // FormData ê°ì²´ ìƒì„±í•˜ì—¬ Zustandì— ì €ì¥ (ì›ë˜ ì‚¬ìš©í•˜ë˜ ë°©ì‹)
        const formData = new FormData();
        formData.append("image", blob, "captured_face.png");
        setUserImageFile(formData);

        console.log("AI ì§„ë‹¨ - ì–¼êµ´ ì´ë¯¸ì§€ form-dataë¡œ ì €ì¥ ì™„ë£Œ!!!!");
        formData.forEach((value, key) => {
          console.log(`Key: ${key}, Value:`, value);
        });
      }
    }, 300);
  };

  const extractFaceImage = (canvas) => {
    console.log("[extractFaceImage] Called");
    const faceCanvas = document.createElement("canvas");
    const context = faceCanvas.getContext("2d");

    const faceX = canvas.width * 0.35;
    const faceY = canvas.height * 0.28;
    const faceWidth = canvas.width * 0.3;
    const faceHeight = canvas.height * 0.46;

    faceCanvas.width = faceWidth;
    faceCanvas.height = faceHeight;

    context.drawImage(
      canvas,
      faceX,
      faceY,
      faceWidth,
      faceHeight,
      0,
      0,
      faceWidth,
      faceHeight
    );
    return faceCanvas.toDataURL("image/png");
  };

  // ğŸ”¥ Base64 -> Blob ë³€í™˜ í•¨ìˆ˜
  const base64ToBlob = (base64, mimeType) => {
    const byteCharacters = atob(base64.split(",")[1]);
    const byteNumbers = new Array(byteCharacters.length);
    for (let i = 0; i < byteCharacters.length; i++) {
      byteNumbers[i] = byteCharacters.charCodeAt(i);
    }
    const byteArray = new Uint8Array(byteNumbers);
    return new Blob([byteArray], { type: mimeType });
  };

  const sendImagesToServer = async (formData) => {
    try {
      // 10. AI ì§„ë‹¨ API í˜¸ì¶œ
      const aiResponse = await axios.post(
        `${apiBaseUrl}/api/consult/ai`,
        formData,
        {
          headers: {
            "Content-Type": "multipart/form-data",
          },
        }
      );
      console.log("Server Response (AI ì§„ë‹¨ ê²°ê³¼):", aiResponse.data);

      // ìƒíƒœ ì—…ë°ì´íŠ¸
      setUserPersonalId(aiResponse.data.results[0].personal_id); //ì—¬ê¸°ì— Userì˜ í¼ìŠ¤ë„ì»¬ëŸ¬ ID ì €ì¥, userPersonalIdê°€ì ¸ë‹¤ ì¨ì•¼í•¨
      setResults(aiResponse.data.results);
      setGptSummary(aiResponse.data.gpt_summary); // GPT ì§„ë‹¨ ê²°ê³¼ ì €ì¥, getSummary êº¼ ì¨ì•¼í•¨í•¨

      fetchPersonalColorDetails(userPersonalId); //í¼ìŠ¤ë„ idì— ë§ëŠ” í¼ìŠ¤ë„ì»¬ëŸ¬ ìƒì„¸ì •ë³´ ìµœì‹ í™”


      // 2. QR ìƒì„± API í˜¸ì¶œì„ ìœ„í•œ formData êµ¬ì„±
      const qrFormData = new FormData();
      // ì´¬ì˜ ì‹œ ì €ì¥í•œ faceBlobì„ ì‚¬ìš© (ì´ë¯¸ ì €ì¥í•´ë‘ì–´ì•¼ í•©ë‹ˆë‹¤)
      qrFormData.append("imageUrl", faceBlob, "captured_face.png");

      // AI ê²°ê³¼ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¬ ì •ë³´ê°€ ìˆë‹¤ë©´ ì´ë¥¼ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì§€ì •
      // const result = aiResponse.data.results[0];
      qrFormData.append("bestColor", aiResponse.data.results[0].personal_color);
      qrFormData.append("subColor1", aiResponse.data.results[1].personal_color);
      qrFormData.append("subColor2", aiResponse.data.results[2].personal_color);
      qrFormData.append("message", gptSummary);
      
      // console.log("ì¤€ìˆ˜ì˜ qrí¼ í…ŒìŠ¤íŠ¸", aiResponse.data.results[0].personal_color);
      // console.log("ì¤€ìˆ˜ì˜ qrí¼ í…ŒìŠ¤íŠ¸", aiResponse.data.results[1].personal_color);
      // console.log("ì¤€ìˆ˜ì˜ qrí¼ í…ŒìŠ¤íŠ¸", aiResponse.data.results[2].personal_color);


      // 3. QR API í˜¸ì¶œ
      const qrResponse = await axios.post(
        `${apiBaseUrl}/api/result/qr`,
        qrFormData,
        {
          headers: {
            "Content-Type": "multipart/form-data",
          },
        }
      );
      console.log("QR Response:", qrResponse.data);

      // QR ì´ë¯¸ì§€ë¥¼ Zustandì— ì €ì¥
      setQrImage(qrResponse.data.qr_url);
    } catch (error) {
      console.error("Error sending images to server:", error);
      openModal("í¼ìŠ¤ë„ì»¬ëŸ¬ ì§„ë‹¨ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
      navigate(-1);
    }
  };

  const handleRetake = () => {
    window.location.reload();
  };

  return (
    <div
      style={{
        width: "100%",
        height: "115%",
        position: "relative",
        overflow: "hidden",
      }}
    >
      <DiagFailModalComponent /> {/* ì§„ë‹¨ì‹¤íŒ¨ ëª¨ë‹¬ ì¶”ê°€ */}
      {/* ì´¬ì˜ ì‹œ í™”ë©´ ê¹œë¹¡ì„ */}
      {isFlashing && (
        <div
          style={{
            position: "absolute",
            top: 0,
            left: 0,
            width: "100%",
            height: "100%",
            backgroundColor: "white",
            opacity: 0.8,
            transition: "opacity 0.3s",
            zIndex: 20,
          }}
        />
      )}
      {/* 5ì´ˆ ì¹´ìš´íŠ¸ë‹¤ìš´ */}
      {countdown !== null && (
        <div
          style={{
            position: "absolute",
            top: "50%",
            left: "50%",
            transform: "translate(-50%, -50%)",
            fontSize: "4rem",
            fontWeight: "bold",
            color: "white",
            backgroundColor: "rgba(0, 0, 0, 0.7)",
            padding: "1.5rem 3rem",
            borderRadius: "15px",
            zIndex: 10,
          }}
        >
          {countdown}
        </div>
      )}
      {capturedImage ? (
        <div style={{ width: "100%", height: "100%", position: "relative" }}>
          <img
            src={capturedImage}
            alt="Captured"
            style={{ width: "100%", height: "100%", objectFit: "cover" }}
          />
          <div
            style={{
              position: "absolute",
              bottom: "5%",
              width: "100%",
              display: "flex",
              justifyContent: "center",
              gap: "40px",
              padding: "0 5%",
            }}
          >
            <button
              onClick={handleRetake}
              style={{
                padding: "1rem 2rem",
                fontSize: "1.5rem",
                fontWeight: "bold",
                backgroundColor: "#82DC28",
                color: "white",
                border: "none",
                borderRadius: "10px",
                cursor: "pointer",
                transform: "translateX(-65%)",
              }}
            >
              ë‹¤ì‹œ ì´¬ì˜í•˜ê¸°
            </button>
            <button
              onClick={() => {
                if (userImageFile && faceBlob) {
                  setResults([]); // ê¸°ì¡´ AI ê²°ê³¼ ì´ˆê¸°í™”
                  setGptSummary("");
                  sendImagesToServer(userImageFile); // ë‘ APIë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í˜¸ì¶œ
                  navigate("/LoadingPage", {
                    state: { from: "MediapipeCameraXTimerAI" },
                  });
                }
              }}
              style={{
                padding: "1rem 2rem",
                fontSize: "1.5rem",
                fontWeight: "bold",
                backgroundColor: "#82DC28",
                color: "white",
                border: "none",
                borderRadius: "10px",
                cursor: "pointer",
                transform: "translateX(-15%)",
              }}
            >
              ì§„ë‹¨í•˜ê¸°
            </button>
          </div>
        </div>
      ) : (
        <>
          <video
            ref={videoRef}
            autoPlay
            muted
            style={{
              position: "absolute",
              top: 0,
              left: 0,
              width: "100%",
              height: "100%",
              objectFit: "cover",
              transform: "scaleX(-1)",
            }}
          />

          <canvas
            ref={canvasRef}
            style={{ display: "none" }}
            willreadfrequently="true"
          />

          {/* ì–¼êµ´ ì¸ì‹ ê°€ì´ë“œ ì˜ì—­ */}
          <div
            style={{
              position: "absolute",
              border: "8px dashed yellow",
              width: "30%",
              height: "70%",
              top: "15%",
              left: "35%",
              borderRadius: "50%",
              pointerEvents: "none",
            }}
          />
          <div
            style={{
              position: "absolute",
              top: "5%",
              left: "50%",
              transform: "translateX(-50%)",
              color: "black",
              fontWeight: "bold",
              fontSize: "24px",
              textAlign: "center",
              pointerEvents: "none",
            }}
          >
            ì–¼êµ´ì„ ê°€ì´ë“œë¼ì¸ì— ë§ê²Œ ìœ„ì¹˜ì‹œì¼œ ì£¼ì„¸ìš”.
          </div>

          {showCaptureButton && (
            <div
              style={{
                position: "absolute",
                bottom: "40%",
                left: "50%",
                transform: "translateX(-50%)",
              }}
            >
              <button
                onClick={handleCapture}
                style={{
                  padding: "1.2rem 2.5rem",
                  fontSize: "1.6rem",
                  fontWeight: "bold",
                  backgroundColor: "#82DC28",
                  color: "white",
                  border: "none",
                  borderRadius: "12px",
                  cursor: "pointer",
                }}
              >
                ì´¬ì˜í•˜ê¸°
              </button>
            </div>
          )}
        </>
      )}
    </div>
  );
};

export default MediapipeCameraXTimerAI;
