import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import accuracy_score
import mediapipe as mp

# âœ… Mediapipe Face Mesh ì„¤ì • (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
mp_face_mesh = mp.solutions.face_mesh

# âœ… ì–¼êµ´ íŠ¹ì • ì˜ì—­ í¬ë¡­ í•¨ìˆ˜
def crop_face_regions(image):
    with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5) as face_mesh:
        results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        if not results.multi_face_landmarks:
            return None

        h, w, _ = image.shape
        face_landmarks = results.multi_face_landmarks[0].landmark

        region_map = {
            "forehead": [10],  # ì´ë§ˆ ì¤‘ì•™
            "left_cheek": [234],  # ì™¼ìª½ ë³¼
            "right_cheek": [454],  # ì˜¤ë¥¸ìª½ ë³¼
            "lips": [13],  # ì…ìˆ  ì¤‘ì•™
            "left_eye": (33, 133),  # ì™¼ìª½ ëˆˆ
            "right_eye": (362, 263)  # ì˜¤ë¥¸ìª½ ëˆˆ
        }

        regions = []
        for key, indices in region_map.items():
            if isinstance(indices, tuple):  # ëˆˆ ì¤‘ì•™ ì¢Œí‘œ
                x = int((face_landmarks[indices[0]].x + face_landmarks[indices[1]].x) / 2 * w)
                y = int((face_landmarks[indices[0]].y + face_landmarks[indices[1]].y) / 2 * h)
            else:  # ë‹¨ì¼ ì¢Œí‘œ
                x = int(face_landmarks[indices[0]].x * w)
                y = int(face_landmarks[indices[0]].y * h)

            size = int(min(h, w) * 0.1)
            x_min, x_max = max(0, x - size // 2), min(w, x + size // 2)
            y_min, y_max = max(0, y - size // 2), min(h, y + size // 2)

            region = image[y_min:y_max, x_min:x_max]
            if region.size > 0:
                resized = cv2.resize(region, (64, 64))
                regions.append(resized)

        if len(regions) == len(region_map):
            return np.concatenate(regions, axis=1)
        return None

# âœ… ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
def load_data(dataset_path, categories):
    data, labels = [], []
    for label, category in enumerate(categories):
        category_path = os.path.join(dataset_path, category)
        for file_name in os.listdir(category_path):
            file_path = os.path.join(category_path, file_name)
            image = cv2.imread(file_path)
            if image is not None:
                cropped_image = crop_face_regions(image)
                if cropped_image is not None:
                    data.append(cropped_image)
                    labels.append(label)

    if len(data) == 0 or len(labels) == 0:
        print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        exit()

    return np.array(data) / 255.0, to_categorical(np.array(labels), num_classes=len(categories))

# âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
test_path = "/home/j-i12d106/dataset/dataset_split/test"

categories = [
    "autumn_dark", "autumn_muted", "autumn_strong",
    "spring_light", "spring_bright", "spring_vivid",
    "summer_light", "summer_muted", "summer_bright",
    "winter_dark", "winter_strong", "winter_vivid"
]

X_test, y_test = load_data(test_path, categories)

# âœ… ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (ê²½ë¡œ ìˆ˜ì •)
model_path = "/home/j-i12d106/saved_models/personal_color_classifier.h5"  # ì˜¬ë°”ë¥¸ ê²½ë¡œë¡œ ë³€ê²½
if not os.path.exists(model_path):
    print(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
    exit()

print(f"ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘... {model_path}")
model = load_model(model_path)

# âœ… ëª¨ë¸ í‰ê°€ (ë°°ì¹˜ ì‚¬ì´ì¦ˆ ëª…ì‹œ)
print("ğŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì •í™•ë„ í‰ê°€ ì¤‘...")
y_pred = model.predict(X_test, batch_size=32, verbose=1)
y_pred_labels = np.argmax(y_pred, axis=1)
y_test_labels = np.argmax(y_test, axis=1)

# âœ… ì •í™•ë„ ì¶œë ¥
test_accuracy = accuracy_score(y_test_labels, y_pred_labels)
print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •í™•ë„: {test_accuracy:.4f}")
