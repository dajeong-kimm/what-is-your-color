import os
import cv2
import mediapipe as mp
import numpy as np
import time
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, ReduceLROnPlateau
from tensorflow.keras.utils import to_categorical
import tensorflow as tf

# GPU ì„¤ì • (ìµœì‹  API ì‚¬ìš©)
os.environ['CUDA_VISIBLE_DEVICES'] = '5'
print("TensorFlow ë²„ì „:", tf.__version__)
print("ì‚¬ìš© ê°€ëŠ¥í•œ GPU:", tf.config.list_physical_devices('GPU'))

gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        tf.config.set_logical_device_configuration(
            gpus[0],
            [tf.config.LogicalDeviceConfiguration(memory_limit=16000)]
        )
        print("âœ… GPU ë©”ëª¨ë¦¬ ì œí•œ ì ìš©ë¨ (16GB)")
    except RuntimeError as e:
        print(e)

# Mediapipe Face Mesh ì„¤ì •
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)

# ì–¼êµ´ íŠ¹ì • ì˜ì—­ í¬ë¡­ í•¨ìˆ˜
def crop_face_regions(image):
    results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    if not results.multi_face_landmarks:
        return None

    h, w, _ = image.shape
    face_landmarks = results.multi_face_landmarks[0].landmark

    region_map = {
        "forehead": [10],         # ì´ë§ˆ ì¤‘ì•™
        "left_cheek": [234],       # ì™¼ìª½ ë³¼
        "right_cheek": [454],      # ì˜¤ë¥¸ìª½ ë³¼
        "lips": [13],              # ì…ìˆ  ì¤‘ì•™
        "left_eye": (33, 133),     # ì™¼ìª½ ëˆˆ
        "right_eye": (362, 263)    # ì˜¤ë¥¸ìª½ ëˆˆ
    }

    regions = []
    for key, indices in region_map.items():
        if isinstance(indices, tuple):  # ë‘ ì ì˜ ì¤‘ê°„ ì¢Œí‘œ (ëˆˆ)
            x = int((face_landmarks[indices[0]].x + face_landmarks[indices[1]].x) / 2 * w)
            y = int((face_landmarks[indices[0]].y + face_landmarks[indices[1]].y) / 2 * h)
        else:  # ë‹¨ì¼ ì¢Œí‘œ
            x = int(face_landmarks[indices[0]].x * w)
            y = int(face_landmarks[indices[0]].y * h)

        size = int(min(h, w) * 0.1)
        x_min, x_max = max(0, x - size // 2), min(w, x + size // 2)
        y_min, y_max = max(0, y - size // 2), min(h, y + size // 2)

        region = image[y_min:y_max, x_min:x_max]
        if region.size > 0:
            resized = cv2.resize(region, (64, 64))
            regions.append(resized)

    if len(regions) == len(region_map):
        return np.concatenate(regions, axis=1)  # ì¢Œìš°ë¡œ ê²°í•© (6ì˜ì—­ â†’ 64x384)
    return None

# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
def load_data(dataset_path, categories):
    data, labels = [], []
    for label, category in enumerate(categories):
        category_path = os.path.join(dataset_path, category)
        for file_name in os.listdir(category_path):
            file_path = os.path.join(category_path, file_name)
            image = cv2.imread(file_path)
            if image is not None:
                cropped_image = crop_face_regions(image)
                if cropped_image is not None:
                    data.append(cropped_image)
                    labels.append(label)
    data = np.array(data, dtype=np.float32) / 255.0
    labels = to_categorical(np.array(labels), num_classes=len(categories))
    return data, labels

# í•™ìŠµ ì‹œê°„ê³¼ ë‚¨ì€ ì‹œê°„ ì¶”ì ì„ ìœ„í•œ ì½œë°± í´ë˜ìŠ¤
class TimeHistory(Callback):
    def on_train_begin(self, logs=None):
        self.train_start = time.time()
    
    def on_epoch_begin(self, epoch, logs=None):
        self.epoch_start = time.time()
    
    def on_epoch_end(self, epoch, logs=None):
        epoch_time = time.time() - self.epoch_start
        elapsed_time = time.time() - self.train_start
        remaining_epochs = self.params['epochs'] - (epoch + 1)
        estimated_remaining_time = remaining_epochs * epoch_time
        print(f"ğŸ•’ [Epoch {epoch+1}/{self.params['epochs']}] ê²½ê³¼ ì‹œê°„: {elapsed_time:.2f}s | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {estimated_remaining_time:.2f}s")

# ë°ì´í„° ì¦ê°• ì½”ë“œ ì œê±°ëœ ëª¨ë¸ ìƒì„± í•¨ìˆ˜
def build_model(input_shape, num_classes):
    model = Sequential()
    # MobileNetV2 ê¸°ë°˜ ëª¨ë¸ (ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ ê³ ì •)
    base_model = MobileNetV2(weights="imagenet", include_top=False, input_shape=input_shape)
    base_model.trainable = False
    model.add(base_model)
    model.add(GlobalAveragePooling2D())
    model.add(Dense(256, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.3))
    model.add(Dense(128, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.3))
    model.add(Dense(num_classes, activation='softmax'))
    
    model.compile(optimizer=Adam(learning_rate=0.0005), 
                  loss='categorical_crossentropy', 
                  metrics=['accuracy'])
    return model

def main():
    # ë°ì´í„°ì…‹ ê²½ë¡œ ë° ì¹´í…Œê³ ë¦¬
    train_path = "/home/j-i12d106/dataset/dataset_split/train"
    categories = [
        "autumn_dark", "autumn_muted", "autumn_strong",
        "spring_light", "spring_bright", "spring_vivid",
        "summer_light", "summer_muted", "summer_bright",
        "winter_dark", "winter_strong", "winter_vivid"
    ]
    
    print("ë°ì´í„° ë¡œë“œ ì¤‘...")
    X_train, y_train = load_data(train_path, categories)
    print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {X_train.shape}, {y_train.shape}")

    # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°: 6ê°œ ì˜ì—­ì„ ì¢Œìš°ë¡œ ê²°í•© â†’ (64, 384, 3)
    input_shape = (64, 384, 3)
    
    # Phase 1: MobileNetV2 ê°€ì¤‘ì¹˜ëŠ” ê³ ì •í•˜ê³  ìƒˆ ë¶„ë¥˜ê¸° ì¸µë§Œ í•™ìŠµ
    print("Phase 1: ìƒìœ„ ë¶„ë¥˜ê¸° ì¸µ í•™ìŠµ ì‹œì‘ (ê¸°ë³¸ í•™ìŠµ)...")
    model = build_model(input_shape, len(categories))
    model.summary()

    # ëª¨ë¸ ì €ì¥ ê²½ë¡œ ì„¤ì •
    save_dir = "/home/j-i12d106/saved_models"
    os.makedirs(save_dir, exist_ok=True)
    checkpoint_path_phase1 = os.path.join(save_dir, "personal_color_classifier_phase1.h5")

    # ì½œë°± ì„¤ì •
    checkpoint_phase1 = ModelCheckpoint(checkpoint_path_phase1, save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)
    early_stopping_phase1 = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)
    reduce_lr_phase1 = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)
    time_callback = TimeHistory()

    total_epochs_phase1 = 50

    history = model.fit(
        X_train, y_train,
        validation_split=0.2,
        epochs=total_epochs_phase1,
        batch_size=32,
        callbacks=[checkpoint_phase1, early_stopping_phase1, reduce_lr_phase1, time_callback],
        verbose=1
    )

    # Phase 1 í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ ë¡œë“œ
    model.load_weights(checkpoint_path_phase1)
    print("Phase 1 ì™„ë£Œ. ì´ì œ Fine-Tuning ì§„í–‰...")

    # MobileNetV2ì˜ ìƒìœ„ ì¼ë¶€ ë ˆì´ì–´(ì˜ˆ: ë§ˆì§€ë§‰ 20ê°œ)ë¥¼ í’€ì–´ì„œ ì¬í•™ìŠµ
    for layer in model.layers:
        if "mobilenetv2" in layer.name:
            base_model = layer
            break
    for layer in base_model.layers[:-20]:
        layer.trainable = False
    for layer in base_model.layers[-20:]:
        layer.trainable = True

    # Fine-Tuningì„ ìœ„í•œ ë‚®ì€ í•™ìŠµë¥  ì ìš©
    model.compile(optimizer=Adam(learning_rate=1e-5), 
                  loss='categorical_crossentropy', 
                  metrics=['accuracy'])

    checkpoint_path_phase2 = os.path.join(save_dir, "personal_color_classifier_phase2.h5")
    checkpoint_phase2 = ModelCheckpoint(checkpoint_path_phase2, save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)
    early_stopping_phase2 = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)
    reduce_lr_phase2 = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)

    total_epochs_phase2 = 30
    history_ft = model.fit(
        X_train, y_train,
        validation_split=0.2,
        epochs=total_epochs_phase2,
        batch_size=32,
        callbacks=[checkpoint_phase2, early_stopping_phase2, reduce_lr_phase2, time_callback],
        verbose=1
    )

    # Fine-Tuning ì™„ë£Œ í›„ ëª¨ë¸ ì €ì¥
    model.save(checkpoint_path_phase2)
    print(f"âœ… ëª¨ë¸ Fine-Tuning ì™„ë£Œ ë° ì €ì¥ ì™„ë£Œ: {checkpoint_path_phase2}")
    print(f"ğŸ“ ì €ì¥ëœ ëª¨ë¸ í™•ì¸: {os.listdir(save_dir)}")

if __name__ == '__main__':
    main()
